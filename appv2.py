from dotenv import load_dotenv
import os
import fitz
import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from langchain.embeddings.cohere import CohereEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import LLMChain, LLMMathChain, SequentialChain, TransformChain
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI
from langchain.llms import HuggingFaceHub
from langchain.llms import Cohere


load_dotenv(dotenv_path=".env")

#create a Title for the App
st.title("Resume-Based Job Recommendation and Skill Gap Analysis")
st.header("Upload Your Resume in PDF Format")
pdf = st.file_uploader("Upload your PDF", type="pdf")


# check if the uploaded file is not none
if pdf is not None:
    pdf_reader = PdfReader(pdf)
    text = ""
    
    for page in pdf_reader.pages:
        text += page.extract_text()

    #st.text(text)
    st.text_area("pdf content is displayed below", value=text, height=300)
    
    text_splitter = CharacterTextSplitter(
        separator = "\n",
        chunk_size = 1000,
        chunk_overlap = 200,
        length_function = len
    )

    # split the text intp smaller chunks
    chunks = text_splitter.split_text(text)

    # select the embeddings we want to use
    embeddings = HuggingFaceEmbeddings()

    # create  a knowledge base
    knowledge_base = FAISS.from_texts(chunks, embeddings)

    option = st.selectbox("Choose an option", ["Which job roles align most effectively with my skill set?"], index=None)

    # query = st.text_input("Ask questions")

    if option is not None:
        # search the knowledge base for document
        docs = knowledge_base.similarity_search(option)

        # initialize an Hugging_face model
        llm = HuggingFaceHub()

        # load a summarization chain
        chain = load_qa_chain(llm, chain_type="stuff")

        #run the chain with input document and user option
        response = chain.run(input_documents = docs, question=option)

        # display the response generated by the AI model
        st.success(response)
