from dotenv import load_dotenv
import os
import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
#from langchain.chains import LLMChain, LLMMathChain, SequentialChain, TransformChain
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI


load_dotenv(dotenv_path=".env")

#create a Title for the App
st.title("Resume-Based Job Recommendation and Skill Gap Analysis")
st.header("Upload Your Resume in PDF Format")
pdf = st.file_uploader("Upload your PDF", type="pdf")

# check if the uploaded file is not none
if pdf is not None:
    pdf_reader = PdfReader(pdf)
    text = ""

    for page in pdf_reader.pages:
        text += page.extract_text()
    
    text_splitter = CharacterTextSplitter(
        separator = "\n",
        chunk_size = 1000,
        chunk_overlap = 200,
        length_function = len
    )

    # split the text intp smaller chunks
    chunks = text_splitter.split_text(text)

    embeddings = OpenAIEmbeddings()

    # create  a knowledge base
    knowledge_base = FAISS.from_texts(chunks, embeddings)

    option = st.selectbox("Choose an option", ["Match skills with Job", "Suggest addition skills", "show percentage match per job scale"], index=None)

    # query = st.text_input("Ask questions")

    if option is not None:
        # search the knowledge base for document
        docs = knowledge_base.similarity_search(option)

        # initialize an open AI model
        llm = OpenAI()

        # load a summarization chain
        chain = load_qa_chain(llm, chain_type="stuff")

        #run the chain with input document and user option
        response = chain.run(input_documents = docs, question=option)

        # display the response generated by the AI model
        st.success(response)

    # if option is not None:
    #     # search the knowledge base for document
    #     docs = knowledge_base.similarity_search(option)

    #     # initialize an open AI model
    #     llm = OpenAI()

    #     # load a summarization chain
    #     chain = load_qa_chain(llm, chain_type="stuff")

    #     #run the chain with input document and user option
    #     response = chain.run(input_documents = docs, question=option)

    #     # display the response generated by the AI model
    #     st.success(response)
    # else:
    #     st.write("You selected None.")